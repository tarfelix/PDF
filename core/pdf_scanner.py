import fitz
import re
from unidecode import unidecode
from config import LEGAL_KEYWORDS, PRE_SELECTED, LEGAL_REGEX_PATTERNS

def get_bookmark_ranges(doc: fitz.Document):
    """Extrai marcadores e calcula os intervalos de p√°ginas que eles cobrem."""
    toc = doc.get_toc(simple=False)
    res = []
    # Estrutura do toc: [lvl, title, page, ...]
    for i, item in enumerate(toc):
        lvl, title, page1 = item[0], item[1], item[2]
        
        # Valida√ß√£o b√°sica de p√°gina
        if not (1 <= page1 <= doc.page_count): continue
        
        start0 = page1 - 1
        end0 = doc.page_count - 1 # Default at√© o fim
        
        # Procura o pr√≥ximo marcador de mesmo n√≠vel ou superior para definir o fim
        for j in range(i + 1, len(toc)):
            if toc[j][0] <= lvl:
                end0 = toc[j][2] - 2 # P√°gina anterior ao pr√≥ximo marcador
                break
        
        # Ajuste de limites
        end0 = max(start0, min(end0, doc.page_count - 1))
        
        disp = f"{'‚û°Ô∏è'*(lvl-1)}{'‚Ü™Ô∏è' if lvl>1 else ''} {title} (P√°gs. {start0+1}-{end0+1})"
        
        res.append({
            "id": f"bm_{i}_{page1}",
            "display_text": disp,
            "start_page_0_idx": start0,
            "end_page_0_idx": end0,
            "title": title,
            "level": lvl,
            "source": "bookmark"
        })
    return res

def smart_scan(doc: fitz.Document):
    """
    Varre o conte√∫do textual das p√°ginas para identificar in√≠cios de pe√ßas.
    Retorna lista de dicion√°rios compat√≠vel com bookmarks.
    """
    found_items = []
    
    # 1. Tenta marcadores primeiro (mais confi√°vel se existir)
    bookmarks = get_bookmark_ranges(doc)
    if bookmarks:
        # Se tem bookmarks suficientes, usa eles + scan complementar? 
        # Por enquanto, vamos retornar bookmarks filtrados por legal keywords
        return find_legal_sections(bookmarks)

    # 2. Se n√£o tem marcadores (ou muito poucos), faz scan de texto
    # (Por simplicidade, se bookmarks < 3, ativamos o scan)
    if len(bookmarks) < 3:
        for page_num in range(doc.page_count):
            page = doc[page_num]
            text = page.get_text("text").strip()
            if not text: continue
            
            # Pega os primeiros 500 caracteres para analisar cabe√ßalho
            header_text = text[:500]
            
            # Verifica padr√µes Regex
            matched_cat = None
            for cat, patterns in LEGAL_REGEX_PATTERNS.items():
                for pat in patterns:
                    if re.search(pat, header_text):
                        matched_cat = cat
                        break
                if matched_cat: break
            
            # Se n√£o achou por regex, tenta keywords simples no in√≠cio
            if not matched_cat:
                lines = header_text.split('\n')
                # Analisa as primeiras 5 linhas n√£o vazias
                first_lines = [l.strip().lower() for l in lines if l.strip()][:5]
                for l in first_lines:
                    norm_line = unidecode(l)
                    for cat, kws in LEGAL_KEYWORDS.items():
                        if any(k == norm_line or (len(k)>4 and k in norm_line) for k in kws):
                            matched_cat = cat
                            break
                    if matched_cat: break

            if matched_cat:
                # Evita duplicatas consecutivas da mesma categoria (ex: pagina 1 e 2 detectadas como senten√ßa)
                if found_items and found_items[-1]['category'] == matched_cat and found_items[-1]['start_page_0_idx'] == page_num - 1:
                    # Assume que √© continua√ß√£o, n√£o faz nada
                    pass
                else:
                    found_items.append({
                        "id": f"scan_{page_num}",
                        "display_text": f"üîç {matched_cat} (P√°g. {page_num+1})",
                        "start_page_0_idx": page_num,
                        "end_page_0_idx": doc.page_count - 1, # Ser√° ajustado depois
                        "title": matched_cat,
                        "category": matched_cat,
                        "unique_id": f"scan_{page_num}_{matched_cat}",
                        "preselect": True,
                        "source": "content_scan"
                    })

    # Ajusta intervalos (o fim de uma pe√ßa √© o come√ßo da pr√≥xima - 1)
    for i in range(len(found_items)):
        if i < len(found_items) - 1:
            found_items[i]['end_page_0_idx'] = found_items[i+1]['start_page_0_idx'] - 1
            # Atualiza display text com intervalo correto
            s = found_items[i]['start_page_0_idx'] + 1
            e = found_items[i]['end_page_0_idx'] + 1
            found_items[i]['display_text'] = f"üîç {found_items[i]['title']} (P√°gs. {s}-{e})"
            
    return found_items

def find_legal_sections(bookmarks):
    """Identifica pe√ßas jur√≠dicas nos marcadores baseando-se em palavras-chave."""
    out = []
    for i, bm in enumerate(bookmarks):
        norm = unidecode(bm['title']).lower()
        match = False
        for cat, kws in LEGAL_KEYWORDS.items():
            if any(unidecode(k).lower() in norm for k in kws):
                out.append({
                    **bm,
                    'category': cat,
                    'unique_id': f"legal_{i}_{bm['id']}",
                    'preselect': cat in PRE_SELECTED,
                    'source': 'bookmark_filter'
                })
                match = True
                break
        # Se n√£o deu match, n√£o inclui na lista "legal", ou poder√≠amos incluir como "Outros"
    return out
